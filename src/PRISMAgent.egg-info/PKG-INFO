Metadata-Version: 2.4
Name: prismagent
Version: 0.1.0
Summary: Modular, multi-agent framework with plugâ€‘andâ€‘play storage, tools, and UIs
Author-email: Thomas Bowman <thomas@example.com>
License: MIT
Project-URL: Repository, https://github.com/your-org/prismagent
Project-URL: Documentation, https://github.com/your-org/prismagent/tree/main/docs
Keywords: AI,agents,openai-agents,multi-agent,framework
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Programming Language :: Python :: 3.11
Classifier: Typing :: Typed
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Requires-Dist: openai>=1.23.0
Requires-Dist: openai-agents>=0.0.12
Requires-Dist: pydantic>=2.7
Requires-Dist: httpx>=0.26
Requires-Dist: fastapi>=0.110
Requires-Dist: uvicorn[standard]>=0.29
Requires-Dist: streamlit>=1.33
Provides-Extra: dev
Requires-Dist: ruff>=0.3; extra == "dev"
Requires-Dist: black>=24.4.0; extra == "dev"
Requires-Dist: mypy>=1.9; extra == "dev"
Requires-Dist: pytest>=8.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.23; extra == "dev"
Requires-Dist: pre-commit>=3.7; extra == "dev"
Requires-Dist: types-requests>=2.31; extra == "dev"
Provides-Extra: redis
Requires-Dist: redis[hiredis]>=5.0.0; extra == "redis"
Provides-Extra: vector
Requires-Dist: pinecone-client>=3.0; extra == "vector"
Requires-Dist: qdrant-client>=1.8; extra == "vector"
Requires-Dist: redisvl>=0.5.2; extra == "vector"
Provides-Extra: voice
Requires-Dist: openai-agents[voice]>=0.0.12; extra == "voice"
Provides-Extra: viz
Requires-Dist: openai-agents[viz]>=0.0.12; extra == "viz"

# PRISMAgent ðŸš€

*A modular, multi-agent framework with plug-and-play storage, tools, and UIs.*

---

## 1 Â· Why this repo exists

1. **Rapid prototyping** â€“ Spin up Streamlit + file-based storage in minutes.  
2. **Future-proof** â€“ Add Redis, Supabase (Postgres), Pinecone/Qdrant, Celery/Arq, or a React + Tailwind front-end **without refactoring core code**.  
3. **AI-first extensibility** â€“ Agents, tools, tasks, and even third-party plug-ins are created at runtime through factories; the directory layout simply keeps them discoverable.

---

## 2 Â· High-level architecture

| Layer | Folder | Purpose |
|-------|--------|---------|
| **Config** | `src/project_name/config/` | Single source of truth (Pydantic Settings) for models, storage, env flags. |
| **Engine** | `src/project_name/engine/` | Pure domain logic: `agent_factory`, `runner`, OpenAI Agents hooks. |
| **Tools** | `src/project_name/tools/` | Function tools exposed to LLMs (`spawn_agent`, `web_search`, â€¦). |
| **Storage** | `src/project_name/storage/` | File/Redis/Supabase/Pinecone back-ends behind one interface. |
| **Tasks** | `src/project_name/tasks/` | In-process async task runner; adapters ready for Celery / Arq. |
| **UI** | `src/project_name/ui/` | `streamlit_app/` for dev; `api/` (FastAPI + middleware) for prod. |
| **Plugins** | `src/project_name/plugins/` | Third-party extensions auto-discovered at startup. |
| **Frontend** | `frontend/` | Future Next.js + Tailwind SPA (optional). |
| **Deploy** | `deploy/` | Dockerfile, Compose, CI stub, cloud templates. |
| **Docs** | `docs/`, `mkdocs.yml` | MkDocs site; build with `mkdocs serve`. |
| **Tests** | `tests/` | `unit/`, `integration/`, `e2e/` + shared fixtures. |

---

## 3 Â· Quick start (local dev)

```bash
# 0) prerequisites
#    - Python 3.11+
#    - Docker Desktop (optional but recommended)
#    - (Mac/Win users) Cursor IDE or VS Code

git clone https://github.com/your-org/project_name.git
cd project_name
python -m venv .venv && source .venv/bin/activate
pip install -e ".[dev,env]"  # installs main + dev extras + dotenv

# Create an environment file
cp .env.example .env
# Edit .env with your OpenAI API key and other settings

# 1) run Streamlit prototype
streamlit run src/project_name/ui/streamlit_app/main.py
# open http://localhost:8501

# 2) run FastAPI (for React/mobile)
uvicorn project_name.ui.api.fastapi_app:app --reload --port 8000
# open http://localhost:8000/docs

# 3) run unit tests
pytest -m "unit"
```

### Docker one-liner

```bash
docker compose -f deploy/docker-compose.yml up --build
# API on :8000, Streamlit on :8501, Redis mock on :6379
```

---

## 4 Â· Configuring storage back-ends

Edit **`.env`** file or set environment variables:

```bash
# File-based (default)
STORAGE_BACKEND=memory
# Redis
STORAGE_BACKEND=redis
REDIS_URL=redis://localhost:6379/0
# Supabase (Postgres)
STORAGE_BACKEND=supabase
SUPABASE_URL=https://xyz.supabase.co
SUPABASE_KEY=your_service_key
# Pinecone / Qdrant
STORAGE_BACKEND=vector
VECTOR_PROVIDER=pinecone
PINECONE_API_KEY=...
```

The application swaps implementations at runtimeâ€”no code changes.

---

## 5 Â· Environment Variables

PRISMAgent uses environment variables for configuration. You can set these in a `.env` file in the root directory, or by setting them in your environment.

### Creating a .env file

```bash
# Copy the example file
cp .env.example .env

# Edit the file with your settings
nano .env
```

### Required Environment Variables

- `OPENAI_API_KEY`: Your OpenAI API key

### Optional Environment Variables

- `DEFAULT_MODEL`: Default model to use (default: "o3-mini")
- `MODEL_TEMPERATURE`: Temperature for model generation (default: 0.7)
- `MODEL_MAX_TOKENS`: Maximum tokens to generate (default: 1000)
- `STORAGE_BACKEND`: Storage backend to use (default: "memory")
- `STORAGE_PATH`: Path for file storage (default: "./data")
- `LOG_LEVEL`: Logging level (default: "INFO")

See `.env.example` for a complete list of available configuration options.

---

## 6 Â· Adding your own pieces

### âž¤ New tool

```python
# src/project_name/tools/greet.py
from agents import function_tool

@function_tool
def greet(name: str) -> str:
    return f"Hello, {name}!"
```

The `agent_factory` auto-discovers it (or list it explicitly).

### âž¤ New plug-in

```python
# my_plugin/__init__.py
from project_name.plugins.registry import register_plugin

@register_plugin
class JokePlugin:
    name = "joke_plugin"
    tools = ["tell_joke"]
```

Copy into `plugins/` or `pip install my_plugin`; it shows up next launch.

### âž¤ Background task

```python
from project_name.tasks.runner import run_task

async def nightly_cleanup():
    ...

run_task(nightly_cleanup, schedule="0 3 * * *")  # cron, in-process
```

---

## 7 Â· Deployment cheat-sheet

| Scenario | Command |
|----------|---------|
| Local dev containers | `docker compose up --build` |
| GitHub Actions CI | Push â†’ `.github/workflows/ci.yml` runs tests + builds image |
| Cloud Run (GCP) | `gcloud run deploy --source .` |
| AWS ECS Fargate | Edit `deploy/cloud/aws/ecs-taskdef.json` â†’ `aws ecs register-task-definition` |
| Azure Container Apps | `az containerapp up --source .` |

*All cloud manifests are placeholdersâ€”swap IDs/regions, then commit.*

---

## 8 Â· Testing matrix

```text
tests/
â”œâ”€ unit/          # pure Python, no I/O
â”œâ”€ integration/   # hits Redis / vector mocks
â””â”€ e2e/           # spins Docker Compose, calls live REST endpoints
```

Run all in CI (`pytest -m "not slow"`).  
Mark slow or external tests with `@pytest.mark.integration` or `@pytest.mark.e2e`.

---

## 9 Â· Contributing

1. Fork + feature branch  
2. `pre-commit install` (Black, Ruff, Mypy run auto)  
3. Add or update testsâ€”coverage must not drop  
4. Open PR â†’ CI must pass  
5. One maintainer review + squash merge

---

## 10 Â· Roadmap

- [ ] Auth + rate-limit middleware  
- [ ] Vector memory RAG integration  
- [ ] React/Tailwind front-end (Next.js)  
- [ ] Celery/Arq driver in `tasks/`  
- [ ] Helm chart & Terraform modules  

> **Questions?** Open an issue or join the Discord. Happy hacking! ðŸŽ‰
